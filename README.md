# Pedro_laptop_proyecto_final_ML

En este repositorio, compartimos el c√≥digo en python de un modelo de Machine Learning de predicci√≥n de precios de ordenadores port√°tiles. Este trabajo parte desde un dataset sin organizar, con la mayor parte de la informaci√≥n en una sola columna. Por lo tanto, se puede apreciar el trabajo de limpieza, EDA y feature engineering (o ingenier√≠a de variables), el entrenamiento de diferentes modelos con pipeline, la b√∫squeda de los mejores hiperpar√°metros con Cross Validation (o validaci√≥n cruzada) y toda la l√≥gica utilizada para el desarrollo de este modelo.

# üìå Predicci√≥n de precios de ordenadores port√°tiles üíª
Este proyecto desarrolla un modelo de Machine Learning para predecir el precio de un port√°til a partir de sus caracter√≠sticas t√©cnicas (RAM, CPU, GPU, almacenamiento, peso, etc.).
El trabajo se ha realizado como proyecto final del bootcamp de Data, aplicando todo el pipeline completo:
Adquisici√≥n de datos.

Limpieza y an√°lisis exploratorio (EDA).
Feature engineering.
Entrenamiento y evaluaci√≥n de modelos.
Interpretaci√≥n de resultados.
Despliegue en una aplicaci√≥n web con Streamlit.


## üîé Dataset
Fuente: el dataset utilizado es un csv fruto de la extracci√≥n, a trav√©s de web scrapping, de m√°s de 1.700 ejemplos reales de ordenadores en Amazon.

Target: Price (precio del port√°til).
Variables principales:
Brand: marca del port√°til.
CPU / GPU: procesador y tarjeta gr√°fica.
RAM, Storage, Weight: caracter√≠sticas t√©cnicas.
Rating: puntuaci√≥n de usuarios.

OS: Sistema operativo



## ‚öôÔ∏è Metodolog√≠a
EDA y limpieza
Tratamiento de nulos.
Normalizaci√≥n de texto (CPU, GPU).
Codificaci√≥n de variables categ√≥ricas.
Visualizaciones: distribuci√≥n de precios, boxplots por marca, correlaciones.
Modelado
Modelos probados:
Regresi√≥n Lineal
Ridge / Lasso
Random Forest
Gradient Boosting (incluyendo variante con p√©rdida Huber y target log-transformado)
XGBoost
KMeans (no supervisado, clustering de port√°tiles)
Selecci√≥n de hiperpar√°metros con GridSearchCV.
Evaluaci√≥n
M√©tricas: MAE, RMSE, R¬≤.
Gr√°ficas: real vs predicho, distribuci√≥n de errores, curva de aprendizaje.
Importancia de variables.
Modelo final
Guardado en models/final_model.pkl. El modelo final elegido ha sido RandomForest

## üöÄ App en Streamlit
Se ha creado una aplicaci√≥n en Streamlit para probar el modelo f√°cilmente:
### Ejecuci√≥n local
Instalar dependencias:

 pip install -r app_streamlit/requirements.txt

Ejecutar la app:

 streamlit run app_streamlit/app.py

Subir un CSV con las mismas columnas que el dataset de entrenamiento.
La app muestra:
Tabla con predicciones.
KPIs (precio medio, min, max).
Gr√°ficas (distribuci√≥n de predicciones, comparaci√≥n real vs predicho).
Bot√≥n para descargar resultados.

## üìä Resultados principales
El modelo final obtuvo un MAE ‚âà 264 ‚Ç¨ y un R2 de 0.746

Variables m√°s importantes en la predicci√≥n: Brand, CPU y RAM, CPU

Buen equilibrio entre interpretabilidad y rendimiento.

## üìå Conclusiones y mejoras
La predicci√≥n de precios de port√°tiles es viable y √∫til para e-commerce o comparadores.
El despliegue con Streamlit permite usar el modelo de manera sencilla.
Mejoras posibles:
Ampliar dataset con m√°s productos y m√°s actualizados. Tambi√©n ser√≠a interesante utilizar el modelo con datasets de diferentes momentos del a√±o para hacer una comparativa de cada √©poca (verano, rebajas, navidad‚Ä¶)
Explorar modelos m√°s avanzados (LightGBM, CatBoost).

